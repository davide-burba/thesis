{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRSA\n",
    "\n",
    "This notebook implements the DRSA survival model for Heart Failure patients (with functional covariates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from lifelines.utils import concordance_index\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.drsa_utils import *\n",
    "from utils.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../../data/main_process_preprocessed_data.csv')\n",
    "test = pd.read_csv('../../data/main_process_preprocessed_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Arbitrary) maximum survival time: 10.0 years\n",
      "Number of time steps: 60\n",
      "Size time step: 2.0 months\n"
     ]
    }
   ],
   "source": [
    "# set time windows parameters\n",
    "T_max = 365*10\n",
    "n_times = int(T_max/60)\n",
    "# discretise time\n",
    "df['discretised_time_event'] = [int(v) for v in df.time_event/T_max*n_times]\n",
    "times = np.arange(n_times).reshape(-1,1,1)\n",
    "\n",
    "print('(Arbitrary) maximum survival time:',np.round(T_max/365,1),'years')\n",
    "print('Number of time steps:',n_times)\n",
    "print('Size time step:',np.round(T_max/n_times/30,1),'months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy sex\n",
    "df['sexM'] = [1 if v == 'M' else 0 for v in df.sex]\n",
    "test['sexM'] = [1 if v == 'M' else 0 for v in test.sex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set features\n",
    "features = ['sexM', 'age_in','ACE_PC1', 'ACE_PC2','beta_PC1', 'beta_PC2','aldosteronics_PC1','aldosteronics_PC2','hospitalisation_PC1', 'hospitalisation_PC2']\n",
    "\n",
    "X,X_test = df[features],test[features]\n",
    "y = df.discretised_time_event\n",
    "true_times = df.time_event\n",
    "status = df.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "mean = X.mean()\n",
    "std = X.std()\n",
    "X -= mean\n",
    "X /= std\n",
    "X_test -= mean\n",
    "X_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train in train/validation (for early stopping)\n",
    "X_train, X_valid, y_train, y_valid, status_train, status_valid = \\\n",
    "    train_test_split(X, y, status, test_size=0.15, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2702, 10), (477, 10), (1362, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat datasets for lstm layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = []\n",
    "for i in X_train.index:\n",
    "    tmp = np.repeat(X_train.loc[i,:].values.reshape(1,1,-1),len(times),axis = 0)\n",
    "    observation_i = np.concatenate([tmp,times], axis = 2)\n",
    "    x_training.append(observation_i)  \n",
    "x_training = np.concatenate(x_training, axis = 1)\n",
    "\n",
    "\n",
    "x_validation = []\n",
    "for i in X_valid.index:\n",
    "    tmp = np.repeat(X_valid.loc[i,:].values.reshape(1,1,-1),len(times),axis = 0)\n",
    "    observation_i = np.concatenate([tmp,times], axis = 2)\n",
    "    x_validation.append(observation_i)\n",
    "x_validation = np.concatenate(x_validation, axis = 1)\n",
    "\n",
    "\n",
    "x_test = []\n",
    "for i in X_test.index:\n",
    "    tmp = np.repeat(X_test.loc[i,:].values.reshape(1,1,-1),len(times),axis = 0)\n",
    "    observation_i = np.concatenate([tmp,times], axis = 2)\n",
    "    x_test.append(observation_i)  \n",
    "x_test = np.concatenate(x_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 2702, 11), (60, 477, 11), (60, 1362, 11))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimensions: time,id,features (added time)\n",
    "x_training.shape, x_validation.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform validation sets in torch tensors\n",
    "X_valid = torch.from_numpy(x_validation.astype('float32'))\n",
    "y_valid = torch.from_numpy(y_valid.values)\n",
    "status_valid = torch.from_numpy(status_valid.values.astype('float32'))\n",
    "X_valid,y_valid,status_valid = X_valid.to(device),y_valid.to(device),status_valid.to(device)\n",
    "\n",
    "# transform test set in tensors\n",
    "X_test = torch.from_numpy(x_test.astype('float32'))\n",
    "X_test = X_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set early stopping parameter\n",
    "max_epochs_no_improvement = 150\n",
    "\n",
    "# build a training data loader\n",
    "trainds= SequenceDataset(x_training, y_train,status_train) \n",
    "params = {'batch_size': 50,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 4}\n",
    " \n",
    "train_dl = DataLoader(trainds, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set criterion\n",
    "criterion = DRSA_Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the network\n",
    "net = DRSA(len(features)+1).to(device)\n",
    "\n",
    "# set optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0    Training Loss:  20905.15    Current Validation Loss:  3036.52    Best Validation Loss:  3036.52\n"
     ]
    }
   ],
   "source": [
    "train_losses,valid_losses = [],[]\n",
    "best_net = DRSA(len(features)+1).to(device)\n",
    "best_loss = 1e10\n",
    "epochs_no_improvement = 0\n",
    "\n",
    "#train\n",
    "for epoch in range(5000):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    net.train()\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        inputs, labels, status = data\n",
    "        # dimensions: time, id, features\n",
    "        inputs = inputs.transpose(0,1)\n",
    "        \n",
    "        # make it use GPU, if you have it\n",
    "        inputs, labels, status = inputs.to(device), labels.to(device), status.to(device) \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize (rows: id; columns: time)\n",
    "        outputs = net(inputs).reshape(n_times,-1).transpose(0,1)\n",
    "        loss = criterion(outputs, labels,status)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # training loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    net.eval()\n",
    "    valid_pred = net(X_valid).reshape(n_times,-1).transpose(0,1)\n",
    "    valid_loss = criterion(valid_pred, y_valid,status_valid).item()\n",
    "    \n",
    "    \n",
    "    # store loss\n",
    "    train_losses.append(running_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    # early stopping\n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        # save weights\n",
    "        best_net.load_state_dict(net.state_dict())\n",
    "        epochs_no_improvement = 0\n",
    "    else:\n",
    "        epochs_no_improvement += 1\n",
    "       \n",
    "    if epochs_no_improvement > max_epochs_no_improvement:\n",
    "        break\n",
    "    \n",
    "    if epoch % 25 == 0:\n",
    "        print('Epoch: ',epoch,'   Training Loss: ',np.round(running_loss,2),'   Current Validation Loss: ',np.round(valid_loss,2),'   Best Validation Loss: ',np.round(best_loss,2))\n",
    "\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, color = 'orange', label = 'training')\n",
    "plt.legend()\n",
    "plt.title('Survival loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(valid_losses, color = 'blue', label = 'validation')\n",
    "plt.legend()\n",
    "plt.title('Survival loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Concordance Index on test set\n",
    "\n",
    "Note: we convert predictions to original time scale and we compare with true time of events; this is done in order to make it comparable with other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net.eval()\n",
    "prediction_test_set = best_net(X_test).reshape(n_times,-1).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute survival time probabilities from hazards\n",
    "prediction_test = [prediction_test_set[:,0].reshape(-1,1)]\n",
    "tmp = (1 - prediction_test_set).cumprod(1)\n",
    "for j in np.arange(1,prediction_test_set.shape[1]):\n",
    "    if j > 0:\n",
    "        prediction_test.append((prediction_test_set[:,j]*tmp[:,j-1]).reshape(-1,1))\n",
    "prediction_test = torch.cat(prediction_test,dim = 1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_survival_times = compute_expected_survival_time(prediction_test_set,n_times,T_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = concordance_index(test.time_event, \n",
    "                  expected_survival_times, \n",
    "                  test.status)\n",
    "\n",
    "print('Concordance Index on test set:',np.round(C*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(best_net.state_dict(), '../../data/DRSA_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
